import os
import json
import pandas as pd
from sklearn.model_selection import train_test_split
from datasets import Dataset

def load_jsonl(file_path):
    """Load JSONL file and return list of dictionaries"""
    data = []
    with open(file_path, 'r', encoding='utf-8') as f:
        for line in f:
            data.append(json.loads(line))
    return data

def process_data(data):
    """Process raw data into structured DataFrame"""
    processed = []
    for item in data:
        # Handle stance values that are lists (take the first value)
        stance = item['stance']
        if isinstance(stance, list):
            stance = stance[0] if stance else "Unrelated"

        processed.append({
            'id': item.get('id', ''),
            'claim': item.get('claim', ''),
            'text': item.get('tweet', ''),  # Field name in original dataset
            'domain': item.get('domain', ''),
            'country': item.get('country', ''),
            'stance': stance
        })
    return pd.DataFrame(processed)

def prepare_datasets(train_file, test_file, label2id, val_split=0.2, random_state=42):
    """Load, process, and prepare datasets for training and evaluation"""
    # Load and process data
    train_data = load_jsonl(train_file)
    test_data = load_jsonl(test_file)
    
    # Create dataframes
    train_df = process_data(train_data)
    test_df = process_data(test_data)
    
    # Train-validation split
    train_df, val_df = train_test_split(
        train_df, 
        test_size=val_split, 
        random_state=random_state, 
        stratify=train_df['stance']
    )
    
    # Prepare input text
    train_df['input_text'] = train_df['claim'] + " [SEP] " + train_df['text']
    val_df['input_text'] = val_df['claim'] + " [SEP] " + val_df['text']
    test_df['input_text'] = test_df['claim'] + " [SEP] " + test_df['text']
    
    # Convert labels
    train_df['label'] = train_df['stance'].map(label2id)
    val_df['label'] = val_df['stance'].map(label2id)
    test_df['label'] = test_df['stance'].map(label2id)
    
    # Convert to HuggingFace datasets
    train_dataset = Dataset.from_pandas(train_df[['input_text', 'label', 'domain', 'country']])
    val_dataset = Dataset.from_pandas(val_df[['input_text', 'label', 'domain', 'country']])
    test_dataset = Dataset.from_pandas(test_df[['input_text', 'label', 'domain', 'country']])
    
    return {
        'train_df': train_df,
        'val_df': val_df,
        'test_df': test_df,
        'train_dataset': train_dataset,
        'val_dataset': val_dataset,
        'test_dataset': test_dataset
    }
